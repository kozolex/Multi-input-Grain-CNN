{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele takie jak maxvit_t, swin_t czy vit_b_16 są dostępne dopiero od nowszych wersji torchvision (od wersji 0.13 lub 0.14). Jeśli użyjesz wcześniejszych wersji, pojawią się błędy, np. AttributeError: module torchvision.models has no attribute maxvit_t.\n",
    "Sugestia: Sprawdź wersję biblioteki torchvision w swoim środowisku:\n",
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "Jeśli używasz starszej wersji, zaktualizuj ją:\n",
    "pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "\n",
    "class MultiInputModel(nn.Module):\n",
    "    def __init__(self, num_classes=11, base_model='efficientnet_v2_m', filter_num_base=4):\n",
    "        super(MultiInputModel, self).__init__()\n",
    "        \n",
    "        # Inicjalizacja modelu RGB\n",
    "        self.base_model = base_model\n",
    "        self.rgb_model, self.base_model_output_size = self._initialize_rgb_model(base_model)\n",
    "        print(f\"Model: {base_model}, base_model_output_size: {self.base_model_output_size}\")\n",
    "\n",
    "        # Inicjalizacja modelu binarnego\n",
    "        self.binary_model = nn.Sequential(\n",
    "            nn.Conv2d(1, filter_num_base * 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(filter_num_base * 2, filter_num_base * 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filter_num_base * 4, 128),  # Dopasowanie wyjścia do 128\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.binary_model_output_size = 128\n",
    "\n",
    "        # Warstwa łącząca\n",
    "        total_input_size = self.base_model_output_size * 2 + self.binary_model_output_size\n",
    "        print(f\"Total input size to fc: {total_input_size}\")\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(total_input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def _initialize_rgb_model(self, base_model):\n",
    "        \"\"\"\n",
    "        Inicjalizuje wybrany model sieci RGB i zwraca model oraz rozmiar jego wyjścia.\n",
    "        \"\"\"\n",
    "        if base_model.startswith('efficientnet'):  # Obsługa EfficientNet i EfficientNetV2\n",
    "            model = getattr(models, base_model)(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            if base_model.startswith('efficientnet_v2'):\n",
    "                return model, 1280  # Wyjście dla EfficientNetV2-M\n",
    "            return model, 1280  # Wyjście dla EfficientNet-B0/B1\n",
    "        \n",
    "        elif base_model == 'googlenet':\n",
    "            model = models.googlenet(pretrained=True)\n",
    "            model.fc = nn.Identity()\n",
    "            return model, 1024\n",
    "        \n",
    "        elif base_model == 'inception_v3':\n",
    "            model = models.inception_v3(pretrained=True, aux_logits=False)  # Wyłącz dodatkowe głowice\n",
    "            model.fc = nn.Identity()\n",
    "            return model, 2048\n",
    "        \n",
    "        elif base_model == 'mobilenet_v2':\n",
    "            model = models.mobilenet_v2(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            return model, 1280\n",
    "        \n",
    "        elif base_model == 'mobilenet_v3_large' or base_model == 'mobilenet_v3_small':\n",
    "            model = getattr(models, base_model)(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            return model, 576\n",
    "        \n",
    "        elif base_model.startswith('resnet'):  # Obsługa ResNet (np. resnet18, resnet50)\n",
    "            model = getattr(models, base_model)(pretrained=True)\n",
    "            model.fc = nn.Identity()\n",
    "            return model, 2048 if '50' in base_model or '101' in base_model else 512  # Rozmiar zależny od wariantu\n",
    "        \n",
    "        elif base_model == 'swin_t':\n",
    "            model = models.swin_t(pretrained=True)\n",
    "            model.head = nn.Identity()\n",
    "            return model, 768\n",
    "        \n",
    "        elif base_model == 'vit_b_16':  # VisionTransformer\n",
    "            model = models.vit_b_16(pretrained=True)\n",
    "            model.heads = nn.Identity()\n",
    "            return model, 768\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported base model: {base_model}\")\n",
    "\n",
    "    def forward(self, t_image, b_image, s_image):\n",
    "        # Ekstrakcja cech dla widoków RGB\n",
    "        t_features = self.rgb_model(t_image)  # Widok T\n",
    "        b_features = self.rgb_model(b_image)  # Widok B\n",
    "        #print(f\"T Features: {t_features.shape}, B Features: {b_features.shape}\")\n",
    "\n",
    "        # Ekstrakcja cech dla obrazu binarnego\n",
    "        s_features = self.binary_model(s_image)\n",
    "        #print(f\"S Features: {s_features.shape}\")\n",
    "\n",
    "        # Połączenie cech\n",
    "        combined_features = torch.cat([t_features, b_features, s_features], dim=1)\n",
    "        #print(f\"Combined Features: {combined_features.shape}\")\n",
    "\n",
    "        # Klasyfikacja\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def get_input_size(base_model):\n",
    "        \"\"\"\n",
    "        Zwraca wymagane wymiary wejściowe dla danego modelu.\n",
    "        \n",
    "        Args:\n",
    "            base_model (str): Nazwa modelu bazowego.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Wymiary wejściowe modelu (wysokość, szerokość).\n",
    "        \"\"\"\n",
    "        if base_model.startswith('efficientnet') or base_model.startswith('mobilenet'):\n",
    "            return (224, 224)  # EfficientNet, MobileNet wymagają 224x224\n",
    "            \n",
    "        elif base_model == 'googlenet':\n",
    "            return (224, 224)  # GoogLeNet wymaga 224x224\n",
    "        \n",
    "        elif base_model == 'inception_v3':\n",
    "            return (299, 299)  # Inception V3 wymaga 299x299\n",
    "        \n",
    "        elif base_model == 'maxvit_t':\n",
    "            return (224, 224)  # MaxVit wymaga 224x224\n",
    "        \n",
    "        elif base_model.startswith('resnet'):\n",
    "            return (224, 224)  # ResNet (np. ResNet50/ResNet101) wymaga 224x224\n",
    "        \n",
    "        elif base_model.startswith('squeezenet'):\n",
    "            return (224, 224)  # SqueezeNet wymaga 224x224\n",
    "        \n",
    "        elif base_model == 'swin_t':\n",
    "            return (224, 224)  # SwinTransformer wymaga 224x224\n",
    "        \n",
    "        elif base_model == 'vit_b_16':  # VisionTransformer\n",
    "            return (224, 224)  # VisionTransformer wymaga 224x224\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported base model: {base_model}\")\n",
    "    def forward2(self, t_image, b_image, s_image):\n",
    "        # Pobierz wymagany rozmiar wejściowy\n",
    "        input_size = self.get_input_size(self.base_model)\n",
    "        \n",
    "        # Weryfikacja wejścia `t_image` i `b_image` (RGB) oraz `s_image` (binary)\n",
    "        assert t_image.shape[-2:] == input_size, f\"Expected T image to be of size {input_size}, but got {t_image.shape[-2:]}\"\n",
    "        assert b_image.shape[-2:] == input_size, f\"Expected B image to be of size {input_size}, but got {b_image.shape[-2:]}\"\n",
    "        assert s_image.shape[-2:] == input_size, f\"Expected S image to be of size {input_size}, but got {s_image.shape[-2:]}\"\n",
    "        \n",
    "        # Ekstrakcja cech dla widoków RGB\n",
    "        t_features = self.rgb_model(t_image)  # Widok T\n",
    "        b_features = self.rgb_model(b_image)  # Widok B\n",
    "\n",
    "        # Ekstrakcja cech dla obrazu binarnego\n",
    "        s_features = self.binary_model(s_image)\n",
    "\n",
    "        # Połączenie cech\n",
    "        combined_features = torch.cat([t_features, b_features, s_features], dim=1)\n",
    "\n",
    "        # Klasyfikacja\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n",
    "    \n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform_rgb=None, transform_binary=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Tworzenie mapowania nazw klas na liczby całkowite\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.data['class'].unique())}\n",
    "\n",
    "        self.transform_rgb = transform_rgb\n",
    "        self.transform_binary = transform_binary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // 3  # Każde ziarno ma 3 obrazy\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Pobierz trzy obrazy\n",
    "        base_idx = idx * 3\n",
    "        t_path = self.data.iloc[base_idx]['path']\n",
    "        b_path = self.data.iloc[base_idx + 1]['path']\n",
    "        s_path = self.data.iloc[base_idx + 2]['path']\n",
    "\n",
    "        t_image = Image.open(t_path).convert(\"RGB\")\n",
    "        b_image = Image.open(b_path).convert(\"RGB\")\n",
    "        s_image = Image.open(s_path).convert(\"L\")  # Obraz binarny\n",
    "\n",
    "        # Transformacje\n",
    "        if self.transform_rgb:\n",
    "            t_image = self.transform_rgb(t_image)\n",
    "            b_image = self.transform_rgb(b_image)\n",
    "        if self.transform_binary:\n",
    "            s_image = self.transform_binary(s_image)\n",
    "\n",
    "        # Pobierz nazwę klasy i przekształć na indeks numeryczny\n",
    "        class_name = self.data.iloc[base_idx]['class']\n",
    "        label = self.class_to_idx[class_name]  # Mapowanie nazwy klasy na numer\n",
    "        label = torch.tensor(label, dtype=torch.long)  # Konwersja na tensor PyTorch\n",
    "\n",
    "        return t_image, b_image, s_image, label\n",
    "\n",
    "#Krok 2: Transformacje dla obrazów RGB i binarnych:\n",
    "# Transformacje dla obrazów RGB\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformacje dla obrazów binarnych\n",
    "transform_binary = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_T_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_T_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: swin_t, base_model_output_size: 768\n",
      "Total input size to fc: 1664\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [35:33<00:00,  1.02batch/s, loss=2.4005]\n",
      "Validation: 100%|██████████| 466/466 [05:05<00:00,  1.53batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [32:55<00:00,  1.10batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [04:48<00:00,  1.61batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [32:57<00:00,  1.10batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [04:48<00:00,  1.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 3\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [32:55<00:00,  1.10batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [04:47<00:00,  1.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [32:54<00:00,  1.10batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [04:48<00:00,  1.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [32:54<00:00,  1.10batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [04:48<00:00,  1.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [32:54<00:00,  1.10batch/s, loss=2.4337]\n",
      "Validation: 100%|██████████| 466/466 [04:48<00:00,  1.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [32:53<00:00,  1.10batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [04:47<00:00,  1.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/mk/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:30<00:00, 11.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: vit_b_16, base_model_output_size: 768\n",
      "Total input size to fc: 1664\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:11<00:00,  1.36batch/s, loss=2.4005]\n",
      "Validation: 100%|██████████| 931/931 [05:48<00:00,  2.67batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:10<00:00,  1.36batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:49<00:00,  2.66batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 2\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:10<00:00,  1.36batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:49<00:00,  2.67batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:10<00:00,  1.36batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:49<00:00,  2.67batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:11<00:00,  1.36batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:48<00:00,  2.67batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:11<00:00,  1.36batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:48<00:00,  2.67batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:10<00:00,  1.36batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:48<00:00,  2.67batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Włącz blokowanie błędów CUDA\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = MultiInputDataset(\"CSV/dataset/train.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "val_dataset = MultiInputDataset(\"CSV/dataset/val.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "test_dataset = MultiInputDataset(\"CSV/dataset/test.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "\n",
    "# List of models to train\n",
    "models_list = ['swin_t', 'vit_b_16']#'efficientnet_b0','efficientnet_v2_m', 'mobilenet_v3_small', 'resnet34', \n",
    "batch_sizes = {\n",
    "    'efficientnet_b0': 32,\n",
    "    'mobilenet_v3_small': 32,\n",
    "    'efficientnet_v2_m': 16,\n",
    "    'resnet34': 32,\n",
    "    'swin_t' :32,\n",
    "    'vit_b_16': 16  \n",
    "}\n",
    "for model_name in models_list:\n",
    "    # Inicjalizacja modelu\n",
    "    model = MultiInputModel(num_classes=11, base_model=model_name)  # Liczba klas\n",
    "    model = model.to(\"cuda\")  # Jeśli używasz GPU\n",
    "\n",
    "    #Dynamicznie przydzielany batch_size\n",
    "\n",
    "    batch_size = batch_sizes[model_name]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Optymalizator i funkcja straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Zapis logów\n",
    "    log_file = f\"training_results/training_log_{model_name}.txt\"\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"epoch,train_loss,val_loss,train_accuracy,val_accuracy,train_precision,val_precision,train_recall,val_recall,train_f1,val_f1\\n\")\n",
    "\n",
    "    # Wczesne zatrzymanie - parametry\n",
    "    early_stop_patience = 5  # Liczba epok bez poprawy\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_path = f\"training_results/best_model_{model_name}.pth\"\n",
    "\n",
    "    # Pętla treningowa\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # === TRENING ===\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true = []\n",
    "        train_pred = []\n",
    "\n",
    "        # Dodaj pasek postępu do pętli batchy\n",
    "        with tqdm(total=len(train_loader), desc=\"Training\", unit=\"batch\") as pbar:\n",
    "            for t_image, b_image, s_image, labels in train_loader:\n",
    "                t_image, b_image, s_image, labels = (\n",
    "                    t_image.to(\"cuda\"),\n",
    "                    b_image.to(\"cuda\"),\n",
    "                    s_image.to(\"cuda\"),\n",
    "                    labels.to(\"cuda\")\n",
    "                )\n",
    "\n",
    "                # Oblicz predykcje i stratę\n",
    "                outputs = model(t_image, b_image, s_image)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_true.extend(labels.cpu().numpy())\n",
    "                train_pred.extend(predicted.cpu().numpy())\n",
    "                pbar.set_postfix({\"loss\": f\"{train_loss / (pbar.n + 1):.4f}\"})  # Wyświetl średnią stratę\n",
    "                pbar.update(1)  # Aktualizuj pasek postępu o 1 krok\n",
    "\n",
    "        train_loss /= len(train_loader)  # Średnia strata w treningu\n",
    "        train_accuracy = accuracy_score(train_true, train_pred)\n",
    "        train_precision = precision_score(train_true, train_pred, average=\"weighted\")\n",
    "        train_recall = recall_score(train_true, train_pred, average=\"weighted\")\n",
    "        train_f1 = f1_score(train_true, train_pred, average=\"weighted\")\n",
    "        #print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # === WALIDACJA ===\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "\n",
    "        with torch.no_grad():  # Wyłącz gradienty\n",
    "            with tqdm(total=len(val_loader), desc=\"Validation\", unit=\"batch\") as pbar_val:\n",
    "                for t_image, b_image, s_image, labels in val_loader:\n",
    "                    t_image, b_image, s_image, labels = (\n",
    "                        t_image.to(\"cuda\"),\n",
    "                        b_image.to(\"cuda\"),\n",
    "                        s_image.to(\"cuda\"),\n",
    "                        labels.to(\"cuda\")\n",
    "                    )\n",
    "                    outputs = model(t_image, b_image, s_image)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_true.extend(labels.cpu().numpy())\n",
    "                    val_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                    pbar_val.update(1)  # Aktualizuj pasek postępu walidacji\n",
    "\n",
    "        val_loss /= len(val_loader)  # Średnia strata w walidacji\n",
    "        val_accuracy = accuracy_score(val_true, val_pred)\n",
    "        val_precision = precision_score(val_true, val_pred, average=\"weighted\")\n",
    "        val_recall = recall_score(val_true, val_pred, average=\"weighted\")\n",
    "        val_f1 = f1_score(val_true, val_pred, average=\"weighted\")\n",
    "        #print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === LOGI ===\n",
    "        #print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{epoch + 1},{train_loss:.4f},{val_loss:.4f},{train_accuracy:.4f},{val_accuracy:.4f},\"\n",
    "                f\"{train_precision:.4f},{val_precision:.4f},{train_recall:.4f},{val_recall:.4f},{train_f1:.4f},{val_f1:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "        # === WCZESNE ZATRZYMANIE ===\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Zapis najlepszego modelu\n",
    "            torch.save(model, best_model_path) #Zapisanie modelu i architektury w pliku pth\n",
    "            print(f\"Best model saved at epoch {epoch + 1}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in val loss for {patience_counter} epoch(s)\")\n",
    "\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "    \"\"\"\n",
    "    # === TEST ===\n",
    "    # Wczytaj najlepszy model\n",
    "    model.load(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for t_image, b_image, s_image, labels in test_loader:\n",
    "            t_image, b_image, s_image, labels = (\n",
    "                t_image.to(\"cuda\"),\n",
    "                b_image.to(\"cuda\"),\n",
    "                s_image.to(\"cuda\"),\n",
    "                labels.to(\"cuda\")\n",
    "            )\n",
    "            outputs = model(t_image, b_image, s_image)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Oblicz dokładność\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Zapis wyniku testu\n",
    "    log_file_test = f\"training_results/test_log_{model_name}.txt\"\n",
    "    with open(log_file_test, \"w\") as f_t:\n",
    "            f_t.write(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \"\"\"\n",
    "    # Zwalnianie pamięci po zakończeniu pracy z modelem\n",
    "    del model  # Usuń model z pamięci\n",
    "    torch.cuda.empty_cache()  # Wyczyść pamięć GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4412/470788982.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(best_model_path)\n"
     ]
    }
   ],
   "source": [
    "# === TEST ===\n",
    "# Wczytaj najlepszy model\n",
    "model = torch.load(best_model_path)\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for t_image, b_image, s_image, labels in test_loader:\n",
    "        t_image, b_image, s_image, labels = (\n",
    "            t_image.to(\"cuda\"),\n",
    "            b_image.to(\"cuda\"),\n",
    "            s_image.to(\"cuda\"),\n",
    "            labels.to(\"cuda\")\n",
    "        )\n",
    "        outputs = model(t_image, b_image, s_image)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Oblicz dokładność\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = correct / total\n",
    "\n",
    "# Zapis wyniku testu\n",
    "log_file_test = f\"training_results/test_log_{model_name}.txt\"\n",
    "with open(log_file_test, \"w\") as f_t:\n",
    "        f_t.write(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Zwalnianie pamięci po zakończeniu pracy z modelem\n",
    "del model  # Usuń model z pamięci\n",
    "torch.cuda.empty_cache()  # Wyczyść pamięć GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
