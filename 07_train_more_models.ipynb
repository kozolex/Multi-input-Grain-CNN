{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele takie jak maxvit_t, swin_t czy vit_b_16 są dostępne dopiero od nowszych wersji torchvision (od wersji 0.13 lub 0.14). Jeśli użyjesz wcześniejszych wersji, pojawią się błędy, np. AttributeError: module torchvision.models has no attribute maxvit_t.\n",
    "Sugestia: Sprawdź wersję biblioteki torchvision w swoim środowisku:\n",
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "Jeśli używasz starszej wersji, zaktualizuj ją:\n",
    "pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MultiInputModel(nn.Module):\n",
    "    def __init__(self, num_classes=11, base_model='efficientnet_b0', filter_num_base=4):\n",
    "        super(MultiInputModel, self).__init__()\n",
    "        \n",
    "        # Wybierz wstępnie przetrenowany model dla obrazów RGB\n",
    "        self.base_model = base_model\n",
    "        self.rgb_model, self.base_model_output_size = self._initialize_rgb_model(base_model)\n",
    "\n",
    "        # Sieć dla obrazu binarnego (widok S)\n",
    "        input_size_binary = filter_num_base * 4\n",
    "        self.binary_model = nn.Sequential(\n",
    "            nn.Conv2d(1, filter_num_base * 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(filter_num_base * 2, filter_num_base * 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size_binary, 128),  # Dynamiczne wejście w pełni połączonej warstwy\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Warstwa łącząca\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model_output_size * 2 + filter_num_base * 32, 512),  # Wyjście RGB x2 + wyjście binarne\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def _initialize_rgb_model(self, base_model):\n",
    "        \"\"\"\n",
    "        Inicjalizuje wybrany model sieci RGB i zwraca model oraz rozmiar jego wyjścia.\n",
    "        \"\"\"\n",
    "        if base_model.startswith('efficientnet'):  # Obsługa EfficientNet i EfficientNetV2\n",
    "            model = getattr(models, base_model)(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            return model, 1280 if 'b' in base_model else 1408  # 1280 dla EfficientNet-B0/B1, 1408 dla V2-S\n",
    "        \n",
    "        elif base_model == 'googlenet':\n",
    "            model = models.googlenet(pretrained=True)\n",
    "            model.fc = nn.Identity()\n",
    "            return model, 1024\n",
    "        \n",
    "        elif base_model == 'inception_v3':\n",
    "            model = models.inception_v3(pretrained=True, aux_logits=False)  # Wyłącz dodatkowe głowice\n",
    "            model.fc = nn.Identity()\n",
    "            return model, 2048\n",
    "        \n",
    "        elif base_model == 'maxvit_t':\n",
    "            model = models.maxvit_t(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            return model, 512\n",
    "        \n",
    "        elif base_model == 'mobilenet_v2':\n",
    "            model = models.mobilenet_v2(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            return model, 1280\n",
    "        \n",
    "        elif base_model == 'mobilenet_v3_large' or base_model == 'mobilenet_v3_small':\n",
    "            model = getattr(models, base_model)(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            return model, 1280\n",
    "        \n",
    "        elif base_model.startswith('resnet'):  # Obsługa ResNet (np. resnet18, resnet50)\n",
    "            model = getattr(models, base_model)(pretrained=True)\n",
    "            model.fc = nn.Identity()\n",
    "            return model, 2048 if '50' in base_model or '101' in base_model else 512  # Rozmiar zależny od wariantu\n",
    "        \n",
    "        elif base_model == 'squeezenet1_0' or base_model == 'squeezenet1_1':\n",
    "            model = getattr(models, base_model)(pretrained=True)\n",
    "            model.classifier = nn.Identity()\n",
    "            return model, 1000  # SqueezeNet zawsze ma 1000 wyjść (feature maps)\n",
    "\n",
    "        elif base_model == 'swin_t':\n",
    "            model = models.swin_t(pretrained=True)\n",
    "            model.head = nn.Identity()\n",
    "            return model, 768\n",
    "        \n",
    "        elif base_model == 'vit_b_16':  # VisionTransformer\n",
    "            model = models.vit_b_16(pretrained=True)\n",
    "            model.heads = nn.Identity()\n",
    "            return model, 768\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported base model: {base_model}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_input_size(base_model):\n",
    "        \"\"\"\n",
    "        Zwraca wymagane wymiary wejściowe dla danego modelu.\n",
    "        \n",
    "        Args:\n",
    "            base_model (str): Nazwa modelu bazowego.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Wymiary wejściowe modelu (wysokość, szerokość).\n",
    "        \"\"\"\n",
    "        if base_model.startswith('efficientnet') or base_model.startswith('mobilenet'):\n",
    "            return (224, 224)  # EfficientNet, MobileNet wymagają 224x224\n",
    "            \n",
    "        elif base_model == 'googlenet':\n",
    "            return (224, 224)  # GoogLeNet wymaga 224x224\n",
    "        \n",
    "        elif base_model == 'inception_v3':\n",
    "            return (299, 299)  # Inception V3 wymaga 299x299\n",
    "        \n",
    "        elif base_model == 'maxvit_t':\n",
    "            return (224, 224)  # MaxVit wymaga 224x224\n",
    "        \n",
    "        elif base_model.startswith('resnet'):\n",
    "            return (224, 224)  # ResNet (np. ResNet50/ResNet101) wymaga 224x224\n",
    "        \n",
    "        elif base_model.startswith('squeezenet'):\n",
    "            return (224, 224)  # SqueezeNet wymaga 224x224\n",
    "        \n",
    "        elif base_model == 'swin_t':\n",
    "            return (224, 224)  # SwinTransformer wymaga 224x224\n",
    "        \n",
    "        elif base_model == 'vit_b_16':  # VisionTransformer\n",
    "            return (224, 224)  # VisionTransformer wymaga 224x224\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported base model: {base_model}\")\n",
    "\n",
    "    def forward(self, t_image, b_image, s_image):\n",
    "        # Pobierz wymagany rozmiar wejściowy\n",
    "        input_size = self.get_input_size(self.base_model)\n",
    "        \n",
    "        # Weryfikacja wejścia `t_image` i `b_image` (RGB) oraz `s_image` (binary)\n",
    "        assert t_image.shape[-2:] == input_size, f\"Expected T image to be of size {input_size}, but got {t_image.shape[-2:]}\"\n",
    "        assert b_image.shape[-2:] == input_size, f\"Expected B image to be of size {input_size}, but got {b_image.shape[-2:]}\"\n",
    "        assert s_image.shape[-2:] == input_size, f\"Expected S image to be of size {input_size}, but got {s_image.shape[-2:]}\"\n",
    "        \n",
    "        # Ekstrakcja cech dla widoków RGB\n",
    "        t_features = self.rgb_model(t_image)  # Widok T\n",
    "        b_features = self.rgb_model(b_image)  # Widok B\n",
    "\n",
    "        # Ekstrakcja cech dla obrazu binarnego\n",
    "        s_features = self.binary_model(s_image)\n",
    "\n",
    "        # Połączenie cech\n",
    "        combined_features = torch.cat([t_features, b_features, s_features], dim=1)\n",
    "\n",
    "        # Klasyfikacja\n",
    "        output = self.fc(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform_rgb=None, transform_binary=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Tworzenie mapowania nazw klas na liczby całkowite\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.data['class'].unique())}\n",
    "\n",
    "        self.transform_rgb = transform_rgb\n",
    "        self.transform_binary = transform_binary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // 3  # Każde ziarno ma 3 obrazy\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Pobierz trzy obrazy\n",
    "        base_idx = idx * 3\n",
    "        t_path = self.data.iloc[base_idx]['path']\n",
    "        b_path = self.data.iloc[base_idx + 1]['path']\n",
    "        s_path = self.data.iloc[base_idx + 2]['path']\n",
    "\n",
    "        t_image = Image.open(t_path).convert(\"RGB\")\n",
    "        b_image = Image.open(b_path).convert(\"RGB\")\n",
    "        s_image = Image.open(s_path).convert(\"L\")  # Obraz binarny\n",
    "\n",
    "        # Transformacje\n",
    "        if self.transform_rgb:\n",
    "            t_image = self.transform_rgb(t_image)\n",
    "            b_image = self.transform_rgb(b_image)\n",
    "        if self.transform_binary:\n",
    "            s_image = self.transform_binary(s_image)\n",
    "\n",
    "        # Pobierz nazwę klasy i przekształć na indeks numeryczny\n",
    "        class_name = self.data.iloc[base_idx]['class']\n",
    "        label = self.class_to_idx[class_name]  # Mapowanie nazwy klasy na numer\n",
    "        label = torch.tensor(label, dtype=torch.long)  # Konwersja na tensor PyTorch\n",
    "\n",
    "        return t_image, b_image, s_image, label\n",
    "\n",
    "#Krok 2: Transformacje dla obrazów RGB i binarnych:\n",
    "from torchvision import transforms\n",
    "\n",
    "# Transformacje dla obrazów RGB\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformacje dla obrazów binarnych\n",
    "transform_binary = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m MultiInputDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV/dataset/val.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform_rgb\u001b[38;5;241m=\u001b[39mtransform_rgb, transform_binary\u001b[38;5;241m=\u001b[39mtransform_binary)\n\u001b[1;32m     12\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m MultiInputDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV/dataset/test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform_rgb\u001b[38;5;241m=\u001b[39mtransform_rgb, transform_binary\u001b[38;5;241m=\u001b[39mtransform_binary)\n\u001b[0;32m---> 14\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[43mbatch_size\u001b[49m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Włącz blokowanie błędów CUDA\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = MultiInputDataset(\"CSV/dataset/train.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "val_dataset = MultiInputDataset(\"CSV/dataset/val.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "test_dataset = MultiInputDataset(\"CSV/dataset/test.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "\n",
    "# List of models to train\n",
    "models_list = [ 'efficientnet_v2_m', 'mobilenet_v3_small', 'resnet34', 'swin_t', 'vit_b_16']#'efficientnet_b0',\n",
    "batch_sizes = {\n",
    "    'efficientnet_b0': 32,\n",
    "    'efficientnet_v2_m': 16,\n",
    "    'mobilenet_v3_small': 64,\n",
    "    'resnet34': 32,\n",
    "    'swin_t' :16,\n",
    "    'vit_b_16': 8  \n",
    "}\n",
    "for model_name in models_list:\n",
    "    # Inicjalizacja modelu\n",
    "    model = MultiInputModel(num_classes=11, base_model=model_name)  # Liczba klas\n",
    "    model = model.to(\"cuda\")  # Jeśli używasz GPU\n",
    "\n",
    "    #Dynamicznie przydzielany batch_size\n",
    "\n",
    "    batch_size = batch_sizes[model_name]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Optymalizator i funkcja straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Zapis logów\n",
    "    log_file = f\"training_results/training_log_{model_name}.txt\"\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Epoch, Train Loss, Val Loss\\n\")\n",
    "\n",
    "    # Wczesne zatrzymanie - parametry\n",
    "    early_stop_patience = 5  # Liczba epok bez poprawy\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_path = f\"training_results/best_model_{model_name}.pth\"\n",
    "\n",
    "    # Pętla treningowa\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # === TRENING ===\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        # Dodaj pasek postępu do pętli batchy\n",
    "        with tqdm(total=len(train_loader), desc=\"Training\", unit=\"batch\") as pbar:\n",
    "            for t_image, b_image, s_image, labels in train_loader:\n",
    "                t_image, b_image, s_image, labels = (\n",
    "                    t_image.to(\"cuda\"),\n",
    "                    b_image.to(\"cuda\"),\n",
    "                    s_image.to(\"cuda\"),\n",
    "                    labels.to(\"cuda\")\n",
    "                )\n",
    "\n",
    "                # Oblicz predykcje i stratę\n",
    "                outputs = model(t_image, b_image, s_image)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                pbar.set_postfix({\"loss\": f\"{train_loss / (pbar.n + 1):.4f}\"})  # Wyświetl średnią stratę\n",
    "                pbar.update(1)  # Aktualizuj pasek postępu o 1 krok\n",
    "\n",
    "        train_loss /= len(train_loader)  # Średnia strata w treningu\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # === WALIDACJA ===\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():  # Wyłącz gradienty\n",
    "            with tqdm(total=len(val_loader), desc=\"Validation\", unit=\"batch\") as pbar_val:\n",
    "                for t_image, b_image, s_image, labels in val_loader:\n",
    "                    t_image, b_image, s_image, labels = (\n",
    "                        t_image.to(\"cuda\"),\n",
    "                        b_image.to(\"cuda\"),\n",
    "                        s_image.to(\"cuda\"),\n",
    "                        labels.to(\"cuda\")\n",
    "                    )\n",
    "                    outputs = model(t_image, b_image, s_image)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    pbar_val.update(1)  # Aktualizuj pasek postępu walidacji\n",
    "\n",
    "        val_loss /= len(val_loader)  # Średnia strata w walidacji\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === LOGI ===\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(f\"{epoch + 1}, {train_loss:.4f}, {val_loss:.4f}\\n\")\n",
    "\n",
    "        # === WCZESNE ZATRZYMANIE ===\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Zapis najlepszego modelu\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved at epoch {epoch + 1}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in val loss for {patience_counter} epoch(s)\")\n",
    "\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "\n",
    "    # === TEST ===\n",
    "    # Wczytaj najlepszy model\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for t_image, b_image, s_image, labels in test_loader:\n",
    "            t_image, b_image, s_image, labels = (\n",
    "                t_image.to(\"cuda\"),\n",
    "                b_image.to(\"cuda\"),\n",
    "                s_image.to(\"cuda\"),\n",
    "                labels.to(\"cuda\")\n",
    "            )\n",
    "            outputs = model(t_image, b_image, s_image)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Oblicz dokładność\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Zapis wyniku testu\n",
    "    log_file_test = f\"training_results/test_log_{model_name}.txt\"\n",
    "    with open(log_file_test, \"w\") as f_t:\n",
    "            f_t.write(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Zwalnianie pamięci po zakończeniu pracy z modelem\n",
    "    del model  # Usuń model z pamięci\n",
    "    torch.cuda.empty_cache()  # Wyczyść pamięć GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = MultiInputDataset(\"CSV/dataset/train.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "val_dataset = MultiInputDataset(\"CSV/dataset/val.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "test_dataset = MultiInputDataset(\"CSV/dataset/test.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Inicjalizacja modelu\n",
    "model = MultiInputModel(num_classes=11)  # Liczba klas\n",
    "model = model.to(\"cuda\")  # Jeśli używasz GPU\n",
    "\n",
    "# Optymalizator i funkcja straty\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Pętla treningowa\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for t_image, b_image, s_image, labels in train_loader:\n",
    "        t_image, b_image, s_image, labels = (\n",
    "            t_image.to(\"cuda\"),\n",
    "            b_image.to(\"cuda\"),\n",
    "            s_image.to(\"cuda\"),\n",
    "            labels.to(\"cuda\")\n",
    "        )\n",
    "\n",
    "        # Oblicz predykcje i stratę\n",
    "        outputs = model(t_image, b_image, s_image)\n",
    "\n",
    "        #print(f\"Outputs shape: {outputs.shape}\")  # Dodaj tę linię\n",
    "        #print(f\"Labels shape: {labels.shape}\")    # Dodaj tę linię\n",
    "        #print(f\"Labels min: {labels.min()}, Labels max: {labels.max()}\")  # Dodaj tę linię\n",
    "        #print(f\"Labels dtype: {labels.dtype}\")  # Dodaj tę linię\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.datasets import ImageFolder\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Data paths\n",
    "train_csv = \"CSV/dataset/train.csv\"\n",
    "val_csv = \"CSV/dataset/val.csv\"\n",
    "test_csv = \"CSV/dataset/test.csv\"\n",
    "\n",
    "# Transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Custom Dataset to handle Data from CSV\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx, 0]\n",
    "        img_path = f\"{self.root_dir}/{img_name}\"\n",
    "        image = Image.open(img_path)\n",
    "        label = int(self.dataframe.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Load CSVs and prepare data\n",
    "train_df = pd.read_csv(train_csv)\n",
    "val_df = pd.read_csv(val_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# Assuming images are stored in a directory named 'images'\n",
    "image_dir = 'images'\n",
    "\n",
    "train_dataset = CustomDataset(train_df, image_dir, transform=data_transforms['train'])\n",
    "val_dataset = CustomDataset(val_df, image_dir, transform=data_transforms['val'])\n",
    "test_dataset = CustomDataset(test_df, image_dir, transform=data_transforms['test'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Function for training\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_corrects = 0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "        print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model\n",
    "\n",
    "# Function for testing\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = test_corrects.double() / len(test_loader.dataset)\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Training and testing each model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes =11\n",
    "for model_name in models_list:\n",
    "    print(f\"\\nTraining {model_name} model:\")\n",
    "    if model_name.startswith('efficientnet') or model_name.startswith('mobilenet'):\n",
    "        model = getattr(models, model_name)(pretrained=True)\n",
    "        num_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(num_features, num_classes)  # Adjust to your number of classes\n",
    "    \n",
    "    elif model_name == 'resnet34':\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    elif model_name == 'vit_b_16':\n",
    "        model = models.vit_b_16(pretrained=True)\n",
    "        num_features = model.head.in_features\n",
    "        model.head = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Train and evaluate\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
    "    print(f\"Finished training {model_name}\")\n",
    "\n",
    "    # Test\n",
    "    print(f\"Testing {model_name} model:\")\n",
    "    test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Twoje klasy i funkcje:\n",
    "# from your_module import MultiInputModel, MultiInputDataset\n",
    "\n",
    "def train_and_evaluate(\n",
    "    models_list,  # Lista nazw modeli bazowych\n",
    "    train_dataset, val_dataset, test_dataset,  # Datasets\n",
    "    num_classes, epochs=20, batch_size=32, learning_rate=0.001,\n",
    "    output_dir='./results', device='cuda'\n",
    "):\n",
    "    # Przygotowanie katalogu wyjściowego\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    log_file_path = os.path.join(output_dir, 'training_logs.txt')\n",
    "\n",
    "    # Zapisz logi\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        log_file.write(f\"Training Logs\\n{'=' * 50}\\n\\n\")\n",
    "\n",
    "    # DataLoadery\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Urządzenie\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for model_name in models_list:\n",
    "        print(f\"Rozpoczynam trenowanie: {model_name}\")\n",
    "        \n",
    "        # Przygotowanie modelu\n",
    "        model = MultiInputModel(num_classes=num_classes, base_model=model_name)\n",
    "        model.to(device)\n",
    "\n",
    "        # Optymalizator i funkcja straty\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Early stopping ustawienia\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        best_model_weights = None\n",
    "\n",
    "        # Wyniki\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accuracies, val_accuracies = [], []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Faza treningowa\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for t_image, b_image, s_image, labels in train_loader:\n",
    "                t_image, b_image, s_image, labels = (\n",
    "                    t_image.to(device),\n",
    "                    b_image.to(device),\n",
    "                    s_image.to(device),\n",
    "                    labels.to(device),\n",
    "                )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(t_image, b_image, s_image)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            train_acc = correct / total\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_acc)\n",
    "\n",
    "            # Faza walidacyjna\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for t_image, b_image, s_image, labels in val_loader:\n",
    "                    t_image, b_image, s_image, labels = (\n",
    "                        t_image.to(device),\n",
    "                        b_image.to(device),\n",
    "                        s_image.to(device),\n",
    "                        labels.to(device),\n",
    "                    )\n",
    "\n",
    "                    outputs = model(t_image, b_image, s_image)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    correct += (preds == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_acc = correct / total\n",
    "            \n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "            # Logowanie\n",
    "            log = f\"{model_name} - Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "            print(log)\n",
    "            with open(log_file_path, 'a') as log_file:\n",
    "                log_file.write(log + '\\n')\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_weights = model.state_dict()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        # Zapisywanie najlepszej wersji modelu\n",
    "        model.load_state_dict(best_model_weights)\n",
    "        model_path = os.path.join(output_dir, f\"{model_name}_best_model.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Model {model_name} zapisano: {model_path}\")\n",
    "\n",
    "        # Tworzenie wykresu krzywej uczenia\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title(f'{model_name} - Loss Curve')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_dir, f\"{model_name}_loss_curve.png\"), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "\n",
    "        # Testowanie i generowanie macierzy pomyłek\n",
    "        cm, y_true, y_pred = test_model(model, test_loader, device)\n",
    "\n",
    "        class_names = list(test_dataset.class_to_idx.keys())\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(f'{model_name} - Confusion Matrix')\n",
    "        plt.savefig(os.path.join(output_dir, f\"{model_name}_confusion_matrix.png\"), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "\n",
    "        # Inne metryki\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        print(f\"Test Accuracy for {model_name}: {acc * 100:.2f}%\")\n",
    "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t_image, b_image, s_image, labels in test_loader:\n",
    "            t_image, b_image, s_image, labels = (\n",
    "                t_image.to(device),\n",
    "                b_image.to(device),\n",
    "                s_image.to(device),\n",
    "                labels.to(device),\n",
    "            )\n",
    "\n",
    "            outputs = model(t_image, b_image, s_image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return cm, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform_rgb=None, transform_binary=None):\n",
    "        \"\"\"\n",
    "        Niestandardowy Dataset wczytujący obrazy z plików CSV.\n",
    "\n",
    "        Args:\n",
    "            csv_file (str): Ścieżka do pliku CSV z polami: class, path, id.\n",
    "            transform_rgb (callable, optional): Transformacje dla obrazów RGB.\n",
    "            transform_binary (callable, optional): Transformacje dla obrazów binarnych (opcjonalne).\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform_rgb = transform_rgb\n",
    "        self.transform_binary = transform_binary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Pobierz wiersz z pliku CSV\n",
    "        row = self.data.iloc[idx]\n",
    "        label = row['class']\n",
    "        path = row['path']\n",
    "\n",
    "        # Załaduj obraz jako RGB (3 kanały)\n",
    "        image_rgb = Image.open(path).convert('RGB')\n",
    "\n",
    "        # Przygotuj obraz binarny (opcjonalne, np. na podstawie nazwy pliku lub innego źródła)\n",
    "        binary_mask_path = path.replace('_T.png', '_S.png')  # Przykład nazwy \"S\" \n",
    "        if os.path.exists(binary_mask_path):\n",
    "            image_binary = Image.open(binary_mask_path).convert('L')\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Nie znaleziono _S {binary_mask_path}\")\n",
    "\n",
    "        # Zastosuj transformacje\n",
    "        if self.transform_rgb:\n",
    "            image_rgb = self.transform_rgb(image_rgb)\n",
    "        if self.transform_binary:\n",
    "            image_binary = self.transform_binary(image_binary)\n",
    "\n",
    "        # Zwróć dane\n",
    "        return image_rgb, image_rgb, image_binary, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transformacje dla obrazów RGB (dopasowane do ImageNet, np. używane w EfficientNet)\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Zmiana rozmiaru obrazu na 224x224\n",
    "    transforms.ToTensor(),  # Konwersja do tensora\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizacja zgodna z ImageNet\n",
    "])\n",
    "\n",
    "# Transformacje dla obrazów binarnych (normalizacja mask do skali 0-1)\n",
    "transform_binary = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Dopasowanie do sieci\n",
    "    transforms.ToTensor(),  # Konwersja do tensora (L na 1 kanał)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ścieżki do danych CSV\n",
    "train_csv = \"CSV/dataset/train.csv\"\n",
    "val_csv = \"CSV/dataset/val.csv\"\n",
    "test_csv = \"CSV/dataset/test.csv\"\n",
    "\n",
    "# Definicja datasetów\n",
    "train_dataset = MultiInputDataset(train_csv, transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "val_dataset = MultiInputDataset(val_csv, transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "test_dataset = MultiInputDataset(test_csv, transform_rgb=transform_rgb, transform_binary=transform_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Przygotowanie DataLoaderów\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Pobierz jeden batch\n",
    "for t_images, b_images, s_images, labels in train_loader:\n",
    "    #print(f\"RGB (T): {t_images.shape}, RGB (B): {b_images.shape}, Binary (S): {s_images.shape}, Labels: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['efficientnet_b0', 'efficientnet_v2_m', 'mobilenet_v3_small', 'resnet34', 'vit_b_16']\n",
    "\n",
    "train_and_evaluate(\n",
    "    models_list=models_list,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    num_classes=11,  # Liczba klas\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.001,\n",
    "    output_dir='./training_results'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
