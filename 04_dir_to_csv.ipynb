{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source dir to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plik CSV wygenerowany i posortowany: CSV/dataset/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_and_sort_dataset_csv(data_dir, output_csv):\n",
    "    \"\"\"\n",
    "    Generuje plik CSV z unikalnymi ID dla każdego ziarna uwzględniając klasę,\n",
    "    a następnie sortuje dane po tych ID.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Ścieżka do głównego katalogu danych.\n",
    "        output_csv (str): Ścieżka do pliku wyjściowego CSV.\n",
    "    \"\"\"\n",
    "    # Lista do przechowywania informacji o plikach\n",
    "    data = []\n",
    "\n",
    "    # Przejdź przez wszystkie pliki w katalogach klas\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        \n",
    "        # Sprawdź, czy to katalog (klasa)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                \n",
    "                # Sprawdź, czy to plik z rozszerzeniem .png\n",
    "                if os.path.isfile(file_path) and file_name.endswith(\".png\"):\n",
    "                    # Wyciągnij id ziarna z nazwy pliku (fragment przed _T/_B/_S)\n",
    "                    seed_id = file_name.split(\"_\")[0]\n",
    "\n",
    "                    # Dodaj dane do listy\n",
    "                    data.append({\n",
    "                        \"class\": class_name,  # Klasa to nazwa katalogu nadrzędnego\n",
    "                        \"seed_id\": seed_id,   # Tymczasowy identyfikator ziarna\n",
    "                        \"path\": file_path,    # Pełna ścieżka do pliku\n",
    "                    })\n",
    "\n",
    "    # Utwórz DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Tworzenie unikalnego identyfikatora (klasa + seed_id)\n",
    "    df['unique_key'] = df['class'] + \"_\" + df['seed_id']\n",
    "\n",
    "    # Mapowanie unikalnych identyfikatorów na numery od 0 w górę\n",
    "    unique_keys = {key: idx for idx, key in enumerate(df['unique_key'].unique())}\n",
    "    df['id'] = df['unique_key'].map(unique_keys)\n",
    "\n",
    "    # Usuń tymczasowe kolumny `seed_id` i `unique_key`\n",
    "    df.drop(columns=['seed_id', 'unique_key'], inplace=True)\n",
    "\n",
    "    # Posortuj DataFrame po `id`\n",
    "    df_sorted = df.sort_values(by=['id'], ascending=True)\n",
    "\n",
    "    # Zapisz do CSV\n",
    "    df_sorted.to_csv(output_csv, index=False)\n",
    "    print(f\"Plik CSV wygenerowany i posortowany: {output_csv}\")\n",
    "\n",
    "# Przykład użycia\n",
    "data_dir = \"/media/512GB_ext/preprocessed_dataset_padded_S_no_changes\"  # Ścieżka do katalogu ze zbiorami danych\n",
    "output_csv = \"CSV/dataset/dataset.csv\"     # Ścieżka do pliku wyjściowego CSV\n",
    "generate_and_sort_dataset_csv(data_dir, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "penguin                                  29017\n",
      "basil                                    29013\n",
      "kws_olof                                 28043\n",
      "jary_skarb_czyzczony                     27570\n",
      "jary_jeczmien_skald_czyszczony_insect    27371\n",
      "kws_atrika                               27048\n",
      "ella                                     27006\n",
      "jary_hajduczek                           26562\n",
      "jary_oberek_czyszczony                   26416\n",
      "nagradowicki                             25706\n",
      "kucyk_insect                             24119\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_elements_per_class(input_csv):\n",
    "    \"\"\"\n",
    "    Zlicza liczbę elementów w każdej klasie na podstawie pliku CSV.\n",
    "\n",
    "    Args:\n",
    "        input_csv (str): Ścieżka do pliku wejściowego CSV.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Liczba elementów w każdej klasie.\n",
    "    \"\"\"\n",
    "    # Wczytaj plik CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Zlicz elementy w każdej klasie\n",
    "    class_counts = df['class'].value_counts()\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "# Przykład użycia\n",
    "input_csv = output_csv\n",
    "class_counts = count_elements_per_class(input_csv)\n",
    "\n",
    "# Wyświetl liczby elementów w każdej klasie\n",
    "print(class_counts)\n",
    "\n",
    "# Opcjonalnie zapisz wynik do pliku CSV\n",
    "class_counts.to_csv(\"class_counts.csv\", header=[\"count\"], index_label=\"class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zaktualizowano ścieżki w pliku: CSV/dataset/test_80.csv\n",
      "Zaktualizowano ścieżki w pliku: CSV/dataset/train_80.csv\n",
      "Zaktualizowano ścieżki w pliku: CSV/dataset/val_80.csv\n"
     ]
    }
   ],
   "source": [
    "#podmianka w plikach CSV\n",
    "from utils import update_csv_paths\n",
    "\n",
    "list_names = [\"test\", \"train\", \"val\"]\n",
    "for name in list_names:\n",
    "    update_csv_paths(\n",
    "        csv_path=f\"CSV/dataset/{name}.csv\",\n",
    "        old_path=\"/media/512GB_ext/preprocessed_dataset_padded_S_no_changes/\",\n",
    "        new_path=\"/media/512GB_ext/pproces_dataset/80_224/\",\n",
    "        output_csv=f\"CSV/dataset/{name}_80.csv\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
