{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import multiModel as mm\n",
    "from multiModel import MultiInputModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "#Zapisz wyniki w \n",
    "path_results = \"training_results_80_224\"\n",
    "# Utwórz katalog docelowy, jeśli nie istnieje\n",
    "if not os.path.exists(path_results):\n",
    "    print(f\"Katalog '{path_results}' utworzony.\")\n",
    "    # Tworzenie katalogu, jeśli nie istnieje\n",
    "    os.makedirs(path_results, exist_ok=True)\n",
    "model_name = \"mm\"\n",
    "# Włącz blokowanie błędów CUDA\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = mm.MultiInputDataset(\"CSV/dataset/train.csv\", transform_rgb=mm.transform_rgb, transform_binary=mm.transform_binary)\n",
    "val_dataset = mm.MultiInputDataset(\"CSV/dataset/val.csv\", transform_rgb=mm.transform_rgb, transform_binary=mm.transform_binary)\n",
    "test_dataset = mm.MultiInputDataset(\"CSV/dataset/test.csv\", transform_rgb=mm.transform_rgb, transform_binary=mm.transform_binary)\n",
    "\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = mm.CustomMultiInputModel(num_classes=11)\n",
    "model = model.to(\"cuda\")  # Jeśli masz GPU\n",
    "\n",
    "#Dynamicznie przydzielany batch_size\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Optymalizator i funkcja straty\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Zapis logów\n",
    "log_file = f\"{path_results}/training_log_{model_name}.txt\"\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"epoch,train_loss,val_loss,train_accuracy,val_accuracy,train_precision,val_precision,train_recall,val_recall,train_f1,val_f1\\n\")\n",
    "\n",
    "# Wczesne zatrzymanie - parametry\n",
    "early_stop_patience = 5  # Liczba epok bez poprawy\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_counter = 0\n",
    "best_model_path = f\"{path_results}/best_model_{model_name}.pth\"\n",
    "\n",
    "# Pętla treningowa\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # === TRENING ===\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_true = []\n",
    "    train_pred = []\n",
    "\n",
    "    # Dodaj pasek postępu do pętli batchy\n",
    "    with tqdm(total=len(train_loader), desc=\"Training\", unit=\"batch\") as pbar:\n",
    "        for t_image, b_image, s_image, labels in train_loader:\n",
    "            t_image, b_image, s_image, labels = (\n",
    "                t_image.to(\"cuda\"),\n",
    "                b_image.to(\"cuda\"),\n",
    "                s_image.to(\"cuda\"),\n",
    "                labels.to(\"cuda\")\n",
    "            )\n",
    "\n",
    "            # Oblicz predykcje i stratę\n",
    "            outputs = model(t_image, b_image, s_image)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "            train_pred.extend(predicted.cpu().numpy())\n",
    "            pbar.set_postfix({\"loss\": f\"{train_loss / (pbar.n + 1):.4f}\"})  # Wyświetl średnią stratę\n",
    "            pbar.update(1)  # Aktualizuj pasek postępu o 1 krok\n",
    "\n",
    "    train_loss /= len(train_loader)  # Średnia strata w treningu\n",
    "    train_accuracy = accuracy_score(train_true, train_pred)\n",
    "    train_precision = precision_score(train_true, train_pred, average=\"weighted\")\n",
    "    train_recall = recall_score(train_true, train_pred, average=\"weighted\")\n",
    "    train_f1 = f1_score(train_true, train_pred, average=\"weighted\")\n",
    "    #print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # === WALIDACJA ===\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "\n",
    "    with torch.no_grad():  # Wyłącz gradienty\n",
    "        with tqdm(total=len(val_loader), desc=\"Validation\", unit=\"batch\") as pbar_val:\n",
    "            for t_image, b_image, s_image, labels in val_loader:\n",
    "                t_image, b_image, s_image, labels = (\n",
    "                    t_image.to(\"cuda\"),\n",
    "                    b_image.to(\"cuda\"),\n",
    "                    s_image.to(\"cuda\"),\n",
    "                    labels.to(\"cuda\")\n",
    "                )\n",
    "                outputs = model(t_image, b_image, s_image)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "                val_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar_val.update(1)  # Aktualizuj pasek postępu walidacji\n",
    "\n",
    "    val_loss /= len(val_loader)  # Średnia strata w walidacji\n",
    "    val_accuracy = accuracy_score(val_true, val_pred)\n",
    "    val_precision = precision_score(val_true, val_pred, average=\"weighted\")\n",
    "    val_recall = recall_score(val_true, val_pred, average=\"weighted\")\n",
    "    val_f1 = f1_score(val_true, val_pred, average=\"weighted\")\n",
    "    #print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # === LOGI ===\n",
    "    #print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(\n",
    "            f\"{epoch + 1},{train_loss:.4f},{val_loss:.4f},{train_accuracy:.4f},{val_accuracy:.4f},\"\n",
    "            f\"{train_precision:.4f},{val_precision:.4f},{train_recall:.4f},{val_recall:.4f},{train_f1:.4f},{val_f1:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "    # === WCZESNE ZATRZYMANIE ===\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Zapis najlepszego modelu\n",
    "        torch.save(model, best_model_path) #Zapisanie modelu i architektury w pliku pth\n",
    "        print(f\"Best model saved at epoch {epoch + 1}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in val loss for {patience_counter} epoch(s)\")\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === TEST ===\n",
    "# Wczytaj najlepszy model\n",
    "model.load(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for t_image, b_image, s_image, labels in test_loader:\n",
    "        t_image, b_image, s_image, labels = (\n",
    "            t_image.to(\"cuda\"),\n",
    "            b_image.to(\"cuda\"),\n",
    "            s_image.to(\"cuda\"),\n",
    "            labels.to(\"cuda\")\n",
    "        )\n",
    "        outputs = model(t_image, b_image, s_image)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Oblicz dokładność\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = correct / total\n",
    "\n",
    "# Zapis wyniku testu\n",
    "log_file_test = f\"training_results/test_log_{model_name}.txt\"\n",
    "with open(log_file_test, \"w\") as f_t:\n",
    "        f_t.write(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Zwalnianie pamięci po zakończeniu pracy z modelem\n",
    "del model  # Usuń model z pamięci\n",
    "torch.cuda.empty_cache()  # Wyczyść pamięć GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
