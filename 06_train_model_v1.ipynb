{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacja modelu w PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MultiInputModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiInputModel, self).__init__()\n",
    "        \n",
    "        # Sieć dla obrazów RGB (widok T i B) - EfficientNet-b0\n",
    "        self.rgb_model = models.efficientnet_b0(pretrained=True)\n",
    "        self.rgb_model.classifier = nn.Identity()  # Usuń ostatnią warstwę (1280 cech)\n",
    "\n",
    "        # Sieć dla obrazu binarnego (widok S)\n",
    "        self.binary_model = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # 1-kanałowe wejście\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * (224 // 4) * (224 // 4), 256),  # Dopasowanie rozmiarów\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Warstwa łącząca\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1280 + 1280 + 256, 512),  # 1280 (T) + 1280 (B) + 256 (S)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, t_image, b_image, s_image):\n",
    "        # Ekstrakcja cech dla widoków RGB\n",
    "        t_features = self.rgb_model(t_image)  # Widok T\n",
    "        b_features = self.rgb_model(b_image)  # Widok B\n",
    "\n",
    "        # Ekstrakcja cech dla obrazu binarnego\n",
    "        s_features = self.binary_model(s_image)\n",
    "\n",
    "        # Połączenie cech\n",
    "        combined_features = torch.cat([t_features, b_features, s_features], dim=1)\n",
    "\n",
    "        # Klasyfikacja\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 1: Przygotowanie danych. Przygotuj dane dla modelu multi-input w formie DataLoader, gdzie każda próbka zawiera trzy obrazy (*_T.png, *_B.png, *_S.png) i ich klasę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform_rgb=None, transform_binary=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Tworzenie mapowania nazw klas na liczby całkowite\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.data['class'].unique())}\n",
    "\n",
    "        self.transform_rgb = transform_rgb\n",
    "        self.transform_binary = transform_binary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // 3  # Każde ziarno ma 3 obrazy\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Pobierz trzy obrazy\n",
    "        base_idx = idx * 3\n",
    "        t_path = self.data.iloc[base_idx]['path']\n",
    "        b_path = self.data.iloc[base_idx + 1]['path']\n",
    "        s_path = self.data.iloc[base_idx + 2]['path']\n",
    "\n",
    "        t_image = Image.open(t_path).convert(\"RGB\")\n",
    "        b_image = Image.open(b_path).convert(\"RGB\")\n",
    "        s_image = Image.open(s_path).convert(\"L\")  # Obraz binarny\n",
    "\n",
    "        # Transformacje\n",
    "        if self.transform_rgb:\n",
    "            t_image = self.transform_rgb(t_image)\n",
    "            b_image = self.transform_rgb(b_image)\n",
    "        if self.transform_binary:\n",
    "            s_image = self.transform_binary(s_image)\n",
    "\n",
    "        # Pobierz nazwę klasy i przekształć na indeks numeryczny\n",
    "        class_name = self.data.iloc[base_idx]['class']\n",
    "        label = self.class_to_idx[class_name]  # Mapowanie nazwy klasy na numer\n",
    "        label = torch.tensor(label, dtype=torch.long)  # Konwersja na tensor PyTorch\n",
    "\n",
    "        return t_image, b_image, s_image, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 2: Transformacje danych\n",
    "Transformacje dla obrazów RGB i binarnych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Transformacje dla obrazów RGB\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformacje dla obrazów binarnych\n",
    "transform_binary = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 3: Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n",
      "Outputs shape: torch.Size([32, 11])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels min: 0, Labels max: 10\n",
      "Labels dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = MultiInputDataset(\"CSV/dataset/train.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "val_dataset = MultiInputDataset(\"CSV/dataset/val.csv\", transform_rgb=transform_rgb, transform_binary=transform_binary)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = MultiInputModel(num_classes=11)  # Liczba klas\n",
    "model = model.to(\"cuda\")  # Jeśli używasz GPU\n",
    "\n",
    "# Optymalizator i funkcja straty\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Pętla treningowa\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for t_image, b_image, s_image, labels in train_loader:\n",
    "        t_image, b_image, s_image, labels = (\n",
    "            t_image.to(\"cuda\"),\n",
    "            b_image.to(\"cuda\"),\n",
    "            s_image.to(\"cuda\"),\n",
    "            labels.to(\"cuda\")\n",
    "        )\n",
    "\n",
    "        # Oblicz predykcje i stratę\n",
    "        outputs = model(t_image, b_image, s_image)\n",
    "\n",
    "        #print(f\"Outputs shape: {outputs.shape}\")  # Dodaj tę linię\n",
    "        #print(f\"Labels shape: {labels.shape}\")    # Dodaj tę linię\n",
    "        #print(f\"Labels min: {labels.min()}, Labels max: {labels.max()}\")  # Dodaj tę linię\n",
    "        #print(f\"Labels dtype: {labels.dtype}\")  # Dodaj tę linię\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
