{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele takie jak maxvit_t, swin_t czy vit_b_16 są dostępne dopiero od nowszych wersji torchvision (od wersji 0.13 lub 0.14). Jeśli użyjesz wcześniejszych wersji, pojawią się błędy, np. AttributeError: module torchvision.models has no attribute maxvit_t.\n",
    "Sugestia: Sprawdź wersję biblioteki torchvision w swoim środowisku:\n",
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "Jeśli używasz starszej wersji, zaktualizuj ją:\n",
    "pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: efficientnet_b0, base_model_output_size: 1280\n",
      "Total input size to fc: 2688\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [27:20<00:00,  1.32batch/s, loss=0.4121]\n",
      "Validation: 100%|██████████| 466/466 [04:27<00:00,  1.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:21<00:00,  1.37batch/s, loss=0.1922]\n",
      "Validation: 100%|██████████| 466/466 [04:29<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [27:36<00:00,  1.31batch/s, loss=0.1542]\n",
      "Validation: 100%|██████████| 466/466 [04:43<00:00,  1.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [27:23<00:00,  1.32batch/s, loss=0.1280]\n",
      "Validation: 100%|██████████| 466/466 [04:40<00:00,  1.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:30<00:00,  1.37batch/s, loss=0.1121]\n",
      "Validation: 100%|██████████| 466/466 [04:27<00:00,  1.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 5\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:26<00:00,  1.37batch/s, loss=0.1051]\n",
      "Validation: 100%|██████████| 466/466 [04:29<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:27<00:00,  1.37batch/s, loss=0.0927]\n",
      "Validation: 100%|██████████| 466/466 [04:29<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:18<00:00,  1.38batch/s, loss=0.0842]\n",
      "Validation: 100%|██████████| 466/466 [04:25<00:00,  1.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:27<00:00,  1.37batch/s, loss=0.0783]\n",
      "Validation: 100%|██████████| 466/466 [04:28<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:43<00:00,  1.35batch/s, loss=0.0787]\n",
      "Validation: 100%|██████████| 466/466 [04:25<00:00,  1.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 10\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:05<00:00,  1.39batch/s, loss=0.0689]\n",
      "Validation: 100%|██████████| 466/466 [04:25<00:00,  1.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:04<00:00,  1.39batch/s, loss=0.0649]\n",
      "Validation: 100%|██████████| 466/466 [04:22<00:00,  1.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:06<00:00,  1.39batch/s, loss=0.0627]\n",
      "Validation: 100%|██████████| 466/466 [04:24<00:00,  1.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:07<00:00,  1.39batch/s, loss=0.0614]\n",
      "Validation: 100%|██████████| 466/466 [04:24<00:00,  1.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:06<00:00,  1.39batch/s, loss=0.0594]\n",
      "Validation: 100%|██████████| 466/466 [04:25<00:00,  1.76batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n",
      "Model: efficientnet_v2_m, base_model_output_size: 1280\n",
      "Total input size to fc: 2688\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:09<00:00,  1.36batch/s, loss=2.4005]\n",
      "Validation: 100%|██████████| 931/931 [05:53<00:00,  2.63batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:08<00:00,  1.36batch/s, loss=2.3975]\n",
      "Validation: 100%|██████████| 931/931 [05:54<00:00,  2.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:09<00:00,  1.36batch/s, loss=2.3970]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:54<00:00,  2.63batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 3\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:35<00:00,  1.35batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:55<00:00,  2.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:11<00:00,  1.36batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:54<00:00,  2.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:13<00:00,  1.36batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:54<00:00,  2.63batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:10<00:00,  1.36batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:53<00:00,  2.63batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [53:09<00:00,  1.36batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [05:55<00:00,  2.62batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mobilenet_v3_small, base_model_output_size: 576\n",
      "Total input size to fc: 1280\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:14<00:00,  1.70batch/s, loss=0.4640]\n",
      "Validation: 100%|██████████| 466/466 [04:11<00:00,  1.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:14<00:00,  1.70batch/s, loss=0.2116]\n",
      "Validation: 100%|██████████| 466/466 [04:11<00:00,  1.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:16<00:00,  1.70batch/s, loss=0.1627]\n",
      "Validation: 100%|██████████| 466/466 [04:10<00:00,  1.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:15<00:00,  1.70batch/s, loss=0.1376]\n",
      "Validation: 100%|██████████| 466/466 [04:10<00:00,  1.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:19<00:00,  1.70batch/s, loss=0.1169]\n",
      "Validation: 100%|██████████| 466/466 [04:11<00:00,  1.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 5\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:16<00:00,  1.70batch/s, loss=0.1049]\n",
      "Validation: 100%|██████████| 466/466 [04:10<00:00,  1.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:15<00:00,  1.70batch/s, loss=0.0940]\n",
      "Validation: 100%|██████████| 466/466 [04:10<00:00,  1.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:20<00:00,  1.70batch/s, loss=0.0863]\n",
      "Validation: 100%|██████████| 466/466 [04:10<00:00,  1.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:20<00:00,  1.70batch/s, loss=0.0816]\n",
      "Validation: 100%|██████████| 466/466 [04:11<00:00,  1.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [21:21<00:00,  1.69batch/s, loss=0.0736]\n",
      "Validation: 100%|██████████| 466/466 [04:10<00:00,  1.86batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n",
      "Model: resnet34, base_model_output_size: 512\n",
      "Total input size to fc: 1152\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:05<00:00,  1.44batch/s, loss=1.9983]\n",
      "Validation: 100%|██████████| 466/466 [04:28<00:00,  1.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:08<00:00,  1.44batch/s, loss=1.3078]\n",
      "Validation: 100%|██████████| 466/466 [04:26<00:00,  1.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 2\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:09<00:00,  1.44batch/s, loss=0.8389]\n",
      "Validation: 100%|██████████| 466/466 [04:35<00:00,  1.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [26:03<00:00,  1.39batch/s, loss=0.6008]\n",
      "Validation: 100%|██████████| 466/466 [04:30<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 4\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:30<00:00,  1.42batch/s, loss=0.4556]\n",
      "Validation: 100%|██████████| 466/466 [04:30<00:00,  1.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 5\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:27<00:00,  1.42batch/s, loss=0.3624]\n",
      "Validation: 100%|██████████| 466/466 [04:30<00:00,  1.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 6\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:29<00:00,  1.42batch/s, loss=0.2994]\n",
      "Validation: 100%|██████████| 466/466 [04:30<00:00,  1.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:26<00:00,  1.42batch/s, loss=0.2537]\n",
      "Validation: 100%|██████████| 466/466 [04:29<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:25<00:00,  1.42batch/s, loss=0.2118]\n",
      "Validation: 100%|██████████| 466/466 [04:29<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 9\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:25<00:00,  1.42batch/s, loss=0.1824]\n",
      "Validation: 100%|██████████| 466/466 [04:28<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:24<00:00,  1.42batch/s, loss=0.1595]\n",
      "Validation: 100%|██████████| 466/466 [04:29<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [24:48<00:00,  1.46batch/s, loss=0.1382]\n",
      "Validation: 100%|██████████| 466/466 [04:26<00:00,  1.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [24:54<00:00,  1.45batch/s, loss=0.1183]\n",
      "Validation: 100%|██████████| 466/466 [04:26<00:00,  1.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [25:13<00:00,  1.44batch/s, loss=0.1076]\n",
      "Validation: 100%|██████████| 466/466 [04:26<00:00,  1.75batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_T_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_T_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n",
      "Model: swin_t, base_model_output_size: 768\n",
      "Total input size to fc: 1664\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:25<00:00,  1.05batch/s, loss=2.4009]\n",
      "Validation: 100%|██████████| 466/466 [05:06<00:00,  1.52batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [33:53<00:00,  1.07batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:07<00:00,  1.52batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 2\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:25<00:00,  1.05batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:07<00:00,  1.51batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:25<00:00,  1.05batch/s, loss=2.3995]\n",
      "Validation: 100%|██████████| 466/466 [05:07<00:00,  1.51batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 4\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:26<00:00,  1.05batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:06<00:00,  1.52batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 5\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:38<00:00,  1.04batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:08<00:00,  1.51batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:26<00:00,  1.05batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:07<00:00,  1.52batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:26<00:00,  1.05batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:06<00:00,  1.52batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:33<00:00,  1.05batch/s, loss=2.3973]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:06<00:00,  1.52batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2172/2172 [34:24<00:00,  1.05batch/s, loss=2.3968]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 466/466 [05:07<00:00,  1.52batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n",
      "Model: vit_b_16, base_model_output_size: 768\n",
      "Total input size to fc: 1664\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:17<00:00,  1.31batch/s, loss=2.3993]\n",
      "Validation: 100%|██████████| 931/931 [06:16<00:00,  2.47batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:20<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:15<00:00,  2.48batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 2\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:21<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:16<00:00,  2.47batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 3\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:20<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:15<00:00,  2.48batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 4\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:22<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:16<00:00,  2.47batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 1 epoch(s)\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:19<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:16<00:00,  2.47batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 2 epoch(s)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:22<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:16<00:00,  2.47batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 3 epoch(s)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:22<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:16<00:00,  2.47batch/s]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 4 epoch(s)\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4344/4344 [55:19<00:00,  1.31batch/s, loss=2.3969]\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Validation: 100%|██████████| 931/931 [06:15<00:00,  2.48batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in val loss for 5 epoch(s)\n",
      "Early stopping triggered. Training stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import multiModel as mm\n",
    "from multiModel import MultiInputModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Zapisz wyniki w \n",
    "path_results = \"training_results_224\"\n",
    "# Włącz blokowanie błędów CUDA\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = mm.MultiInputDataset(\"CSV/dataset/train.csv\", transform_rgb=mm.transform_rgb, transform_binary=mm.transform_binary)\n",
    "val_dataset = mm.MultiInputDataset(\"CSV/dataset/val.csv\", transform_rgb=mm.transform_rgb, transform_binary=mm.transform_binary)\n",
    "test_dataset = mm.MultiInputDataset(\"CSV/dataset/test.csv\", transform_rgb=mm.transform_rgb, transform_binary=mm.transform_binary)\n",
    "\n",
    "# List of models to train\n",
    "models_list = ['efficientnet_b0','efficientnet_v2_m', 'mobilenet_v3_small', 'resnet34','swin_t', 'vit_b_16']#\n",
    "batch_sizes = {\n",
    "    'efficientnet_b0': 32,\n",
    "    'mobilenet_v3_small': 32,\n",
    "    'efficientnet_v2_m': 16,\n",
    "    'resnet34': 32,\n",
    "    'swin_t' :32,\n",
    "    'vit_b_16': 16  \n",
    "}\n",
    "for model_name in models_list:\n",
    "    # Inicjalizacja modelu\n",
    "    model = MultiInputModel(num_classes=11, base_model=model_name)  # Liczba klas\n",
    "    model = model.to(\"cuda\")  # Jeśli używasz GPU\n",
    "\n",
    "    #Dynamicznie przydzielany batch_size\n",
    "\n",
    "    batch_size = batch_sizes[model_name]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Optymalizator i funkcja straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Zapis logów\n",
    "    log_file = f\"{path_results}/training_log_{model_name}.txt\"\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"epoch,train_loss,val_loss,train_accuracy,val_accuracy,train_precision,val_precision,train_recall,val_recall,train_f1,val_f1\\n\")\n",
    "\n",
    "    # Wczesne zatrzymanie - parametry\n",
    "    early_stop_patience = 5  # Liczba epok bez poprawy\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_path = f\"{path_results}/best_model_{model_name}.pth\"\n",
    "\n",
    "    # Pętla treningowa\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # === TRENING ===\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true = []\n",
    "        train_pred = []\n",
    "\n",
    "        # Dodaj pasek postępu do pętli batchy\n",
    "        with tqdm(total=len(train_loader), desc=\"Training\", unit=\"batch\") as pbar:\n",
    "            for t_image, b_image, s_image, labels in train_loader:\n",
    "                t_image, b_image, s_image, labels = (\n",
    "                    t_image.to(\"cuda\"),\n",
    "                    b_image.to(\"cuda\"),\n",
    "                    s_image.to(\"cuda\"),\n",
    "                    labels.to(\"cuda\")\n",
    "                )\n",
    "\n",
    "                # Oblicz predykcje i stratę\n",
    "                outputs = model(t_image, b_image, s_image)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_true.extend(labels.cpu().numpy())\n",
    "                train_pred.extend(predicted.cpu().numpy())\n",
    "                pbar.set_postfix({\"loss\": f\"{train_loss / (pbar.n + 1):.4f}\"})  # Wyświetl średnią stratę\n",
    "                pbar.update(1)  # Aktualizuj pasek postępu o 1 krok\n",
    "\n",
    "        train_loss /= len(train_loader)  # Średnia strata w treningu\n",
    "        train_accuracy = accuracy_score(train_true, train_pred)\n",
    "        train_precision = precision_score(train_true, train_pred, average=\"weighted\")\n",
    "        train_recall = recall_score(train_true, train_pred, average=\"weighted\")\n",
    "        train_f1 = f1_score(train_true, train_pred, average=\"weighted\")\n",
    "        #print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # === WALIDACJA ===\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "\n",
    "        with torch.no_grad():  # Wyłącz gradienty\n",
    "            with tqdm(total=len(val_loader), desc=\"Validation\", unit=\"batch\") as pbar_val:\n",
    "                for t_image, b_image, s_image, labels in val_loader:\n",
    "                    t_image, b_image, s_image, labels = (\n",
    "                        t_image.to(\"cuda\"),\n",
    "                        b_image.to(\"cuda\"),\n",
    "                        s_image.to(\"cuda\"),\n",
    "                        labels.to(\"cuda\")\n",
    "                    )\n",
    "                    outputs = model(t_image, b_image, s_image)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_true.extend(labels.cpu().numpy())\n",
    "                    val_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                    pbar_val.update(1)  # Aktualizuj pasek postępu walidacji\n",
    "\n",
    "        val_loss /= len(val_loader)  # Średnia strata w walidacji\n",
    "        val_accuracy = accuracy_score(val_true, val_pred)\n",
    "        val_precision = precision_score(val_true, val_pred, average=\"weighted\")\n",
    "        val_recall = recall_score(val_true, val_pred, average=\"weighted\")\n",
    "        val_f1 = f1_score(val_true, val_pred, average=\"weighted\")\n",
    "        #print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === LOGI ===\n",
    "        #print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{epoch + 1},{train_loss:.4f},{val_loss:.4f},{train_accuracy:.4f},{val_accuracy:.4f},\"\n",
    "                f\"{train_precision:.4f},{val_precision:.4f},{train_recall:.4f},{val_recall:.4f},{train_f1:.4f},{val_f1:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "        # === WCZESNE ZATRZYMANIE ===\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Zapis najlepszego modelu\n",
    "            torch.save(model, best_model_path) #Zapisanie modelu i architektury w pliku pth\n",
    "            print(f\"Best model saved at epoch {epoch + 1}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in val loss for {patience_counter} epoch(s)\")\n",
    "\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "    \"\"\"\n",
    "    # === TEST ===\n",
    "    # Wczytaj najlepszy model\n",
    "    model.load(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for t_image, b_image, s_image, labels in test_loader:\n",
    "            t_image, b_image, s_image, labels = (\n",
    "                t_image.to(\"cuda\"),\n",
    "                b_image.to(\"cuda\"),\n",
    "                s_image.to(\"cuda\"),\n",
    "                labels.to(\"cuda\")\n",
    "            )\n",
    "            outputs = model(t_image, b_image, s_image)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Oblicz dokładność\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Zapis wyniku testu\n",
    "    log_file_test = f\"training_results/test_log_{model_name}.txt\"\n",
    "    with open(log_file_test, \"w\") as f_t:\n",
    "            f_t.write(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \"\"\"\n",
    "    # Zwalnianie pamięci po zakończeniu pracy z modelem\n",
    "    del model  # Usuń model z pamięci\n",
    "    torch.cuda.empty_cache()  # Wyczyść pamięć GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8517/470788982.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(best_model_path)\n"
     ]
    }
   ],
   "source": [
    "# === TEST ===\n",
    "# Wczytaj najlepszy model\n",
    "model = torch.load(best_model_path)\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for t_image, b_image, s_image, labels in test_loader:\n",
    "        t_image, b_image, s_image, labels = (\n",
    "            t_image.to(\"cuda\"),\n",
    "            b_image.to(\"cuda\"),\n",
    "            s_image.to(\"cuda\"),\n",
    "            labels.to(\"cuda\")\n",
    "        )\n",
    "        outputs = model(t_image, b_image, s_image)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Oblicz dokładność\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = correct / total\n",
    "\n",
    "# Zapis wyniku testu\n",
    "log_file_test = f\"training_results/test_log_{model_name}.txt\"\n",
    "with open(log_file_test, \"w\") as f_t:\n",
    "        f_t.write(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Zwalnianie pamięci po zakończeniu pracy z modelem\n",
    "del model  # Usuń model z pamięci\n",
    "torch.cuda.empty_cache()  # Wyczyść pamięć GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mk/miniconda3/envs/dnn_gpu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: efficientnet_b0, base_model_output_size: 1280\n",
      "Total input size to fc: 2688\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 319/8688 [02:20<1:00:45,  2.30batch/s, loss=2.2858]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import multiModel as mm\n",
    "from multiModel import MultiInputModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Zapisz wyniki w \n",
    "path_results = \"training_results_224\"\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(path_results):\n",
    "    # Create the directory\n",
    "    os.makedirs(path_results)\n",
    "    print(f\"Directory '{path_results}' created.\")\n",
    "\n",
    "\n",
    "# Włącz blokowanie błędów CUDA\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Załaduj dane\n",
    "train_dataset = mm.MultiInputDataset(\"CSV/dataset/train.csv\", transform_rgb=mm.transform_rgb_224, transform_binary=mm.transform_binary_224)\n",
    "val_dataset = mm.MultiInputDataset(\"CSV/dataset/val.csv\", transform_rgb=mm.transform_rgb_224, transform_binary=mm.transform_binary_224)\n",
    "test_dataset = mm.MultiInputDataset(\"CSV/dataset/test.csv\", transform_rgb=mm.transform_rgb_224, transform_binary=mm.transform_binary_224)\n",
    "\n",
    "# List of models to train\n",
    "models_list = ['efficientnet_b0','efficientnet_v2_m', 'mobilenet_v3_small', 'resnet34','swin_t', 'vit_b_16']#\n",
    "batch_sizes = {\n",
    "    'efficientnet_b0': 8,\n",
    "    'mobilenet_v3_small': 32,\n",
    "    'efficientnet_v2_m': 16,\n",
    "    'resnet34': 32,\n",
    "    'swin_t' :32,\n",
    "    'vit_b_16': 16  \n",
    "}\n",
    "for model_name in models_list:\n",
    "    # Inicjalizacja modelu\n",
    "    model = MultiInputModel(num_classes=11, base_model=model_name)  # Liczba klas\n",
    "    model = model.to(\"cuda\")  # Jeśli używasz GPU\n",
    "\n",
    "    #Dynamicznie przydzielany batch_size\n",
    "\n",
    "    batch_size = batch_sizes[model_name]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Optymalizator i funkcja straty\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Zapis logów\n",
    "    log_file = f\"{path_results}/training_log_{model_name}.txt\"\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"epoch,train_loss,val_loss,train_accuracy,val_accuracy,train_precision,val_precision,train_recall,val_recall,train_f1,val_f1\\n\")\n",
    "\n",
    "    # Wczesne zatrzymanie - parametry\n",
    "    early_stop_patience = 5  # Liczba epok bez poprawy\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_path = f\"{path_results}/best_model_{model_name}.pth\"\n",
    "\n",
    "    # Pętla treningowa\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # === TRENING ===\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true = []\n",
    "        train_pred = []\n",
    "\n",
    "        # Dodaj pasek postępu do pętli batchy\n",
    "        with tqdm(total=len(train_loader), desc=\"Training\", unit=\"batch\") as pbar:\n",
    "            for t_image, b_image, s_image, labels in train_loader:\n",
    "                t_image, b_image, s_image, labels = (\n",
    "                    t_image.to(\"cuda\"),\n",
    "                    b_image.to(\"cuda\"),\n",
    "                    s_image.to(\"cuda\"),\n",
    "                    labels.to(\"cuda\")\n",
    "                )\n",
    "\n",
    "                # Oblicz predykcje i stratę\n",
    "                outputs = model(t_image, b_image, s_image)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_true.extend(labels.cpu().numpy())\n",
    "                train_pred.extend(predicted.cpu().numpy())\n",
    "                pbar.set_postfix({\"loss\": f\"{train_loss / (pbar.n + 1):.4f}\"})  # Wyświetl średnią stratę\n",
    "                pbar.update(1)  # Aktualizuj pasek postępu o 1 krok\n",
    "\n",
    "        train_loss /= len(train_loader)  # Średnia strata w treningu\n",
    "        train_accuracy = accuracy_score(train_true, train_pred)\n",
    "        train_precision = precision_score(train_true, train_pred, average=\"weighted\")\n",
    "        train_recall = recall_score(train_true, train_pred, average=\"weighted\")\n",
    "        train_f1 = f1_score(train_true, train_pred, average=\"weighted\")\n",
    "        #print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # === WALIDACJA ===\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "\n",
    "        with torch.no_grad():  # Wyłącz gradienty\n",
    "            with tqdm(total=len(val_loader), desc=\"Validation\", unit=\"batch\") as pbar_val:\n",
    "                for t_image, b_image, s_image, labels in val_loader:\n",
    "                    t_image, b_image, s_image, labels = (\n",
    "                        t_image.to(\"cuda\"),\n",
    "                        b_image.to(\"cuda\"),\n",
    "                        s_image.to(\"cuda\"),\n",
    "                        labels.to(\"cuda\")\n",
    "                    )\n",
    "                    outputs = model(t_image, b_image, s_image)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_true.extend(labels.cpu().numpy())\n",
    "                    val_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                    pbar_val.update(1)  # Aktualizuj pasek postępu walidacji\n",
    "\n",
    "        val_loss /= len(val_loader)  # Średnia strata w walidacji\n",
    "        val_accuracy = accuracy_score(val_true, val_pred)\n",
    "        val_precision = precision_score(val_true, val_pred, average=\"weighted\")\n",
    "        val_recall = recall_score(val_true, val_pred, average=\"weighted\")\n",
    "        val_f1 = f1_score(val_true, val_pred, average=\"weighted\")\n",
    "        #print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === LOGI ===\n",
    "        #print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{epoch + 1},{train_loss:.4f},{val_loss:.4f},{train_accuracy:.4f},{val_accuracy:.4f},\"\n",
    "                f\"{train_precision:.4f},{val_precision:.4f},{train_recall:.4f},{val_recall:.4f},{train_f1:.4f},{val_f1:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "        # === WCZESNE ZATRZYMANIE ===\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Zapis najlepszego modelu\n",
    "            torch.save(model, best_model_path) #Zapisanie modelu i architektury w pliku pth\n",
    "            print(f\"Best model saved at epoch {epoch + 1}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in val loss for {patience_counter} epoch(s)\")\n",
    "\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "    \"\"\"\n",
    "    # === TEST ===\n",
    "    # Wczytaj najlepszy model\n",
    "    model.load(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for t_image, b_image, s_image, labels in test_loader:\n",
    "            t_image, b_image, s_image, labels = (\n",
    "                t_image.to(\"cuda\"),\n",
    "                b_image.to(\"cuda\"),\n",
    "                s_image.to(\"cuda\"),\n",
    "                labels.to(\"cuda\")\n",
    "            )\n",
    "            outputs = model(t_image, b_image, s_image)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Oblicz dokładność\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Zapis wyniku testu\n",
    "    log_file_test = f\"training_results/test_log_{model_name}.txt\"\n",
    "    with open(log_file_test, \"w\") as f_t:\n",
    "            f_t.write(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \"\"\"\n",
    "    # Zwalnianie pamięci po zakończeniu pracy z modelem\n",
    "    del model  # Usuń model z pamięci\n",
    "    torch.cuda.empty_cache()  # Wyczyść pamięć GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
